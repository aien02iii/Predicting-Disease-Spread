{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DengAI: Predicting Disease Spread _ DRIVENDATA Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.引入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "from sklearn import cross_validation, tree, linear_model,metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.觀察原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將前三欄變成索引\n",
    "train_features = pd.read_csv('dengue_features_train.csv',index_col=[0,1,2])\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv',index_col=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>rainingday_for_week_before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sj</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1990</th>\n",
       "      <th>18</th>\n",
       "      <td>1990/4/30</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>292.414286</td>\n",
       "      <td>299.8</td>\n",
       "      <td>...</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1990/5/7</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>293.951429</td>\n",
       "      <td>300.9</td>\n",
       "      <td>...</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1990/5/14</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>295.434286</td>\n",
       "      <td>300.5</td>\n",
       "      <td>...</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1990/5/21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>299.228571</td>\n",
       "      <td>295.310000</td>\n",
       "      <td>301.4</td>\n",
       "      <td>...</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1990/5/28</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>299.664286</td>\n",
       "      <td>295.821429</td>\n",
       "      <td>301.9</td>\n",
       "      <td>...</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     week_start_date   ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "city year weekofyear                                                           \n",
       "sj   1990 18               1990/4/30  0.122600  0.103725  0.198483  0.177617   \n",
       "          19                1990/5/7  0.169900  0.142175  0.162357  0.155486   \n",
       "          20               1990/5/14  0.032250  0.172967  0.157200  0.170843   \n",
       "          21               1990/5/21  0.128633  0.245067  0.227557  0.235886   \n",
       "          22               1990/5/28  0.196200  0.262200  0.251200  0.247340   \n",
       "\n",
       "                      precipitation_amt_mm  reanalysis_air_temp_k  \\\n",
       "city year weekofyear                                                \n",
       "sj   1990 18                         12.42             297.572857   \n",
       "          19                         22.82             298.211429   \n",
       "          20                         34.54             298.781429   \n",
       "          21                         15.36             298.987143   \n",
       "          22                          7.52             299.518571   \n",
       "\n",
       "                      reanalysis_avg_temp_k  reanalysis_dew_point_temp_k  \\\n",
       "city year weekofyear                                                       \n",
       "sj   1990 18                     297.742857                   292.414286   \n",
       "          19                     298.442857                   293.951429   \n",
       "          20                     298.878571                   295.434286   \n",
       "          21                     299.228571                   295.310000   \n",
       "          22                     299.664286                   295.821429   \n",
       "\n",
       "                      reanalysis_max_air_temp_k             ...              \\\n",
       "city year weekofyear                                        ...               \n",
       "sj   1990 18                              299.8             ...               \n",
       "          19                              300.9             ...               \n",
       "          20                              300.5             ...               \n",
       "          21                              301.4             ...               \n",
       "          22                              301.9             ...               \n",
       "\n",
       "                      reanalysis_relative_humidity_percent  \\\n",
       "city year weekofyear                                         \n",
       "sj   1990 18                                     73.365714   \n",
       "          19                                     77.368571   \n",
       "          20                                     82.052857   \n",
       "          21                                     80.337143   \n",
       "          22                                     80.460000   \n",
       "\n",
       "                      reanalysis_sat_precip_amt_mm  \\\n",
       "city year weekofyear                                 \n",
       "sj   1990 18                                 12.42   \n",
       "          19                                 22.82   \n",
       "          20                                 34.54   \n",
       "          21                                 15.36   \n",
       "          22                                  7.52   \n",
       "\n",
       "                      reanalysis_specific_humidity_g_per_kg  \\\n",
       "city year weekofyear                                          \n",
       "sj   1990 18                                      14.012857   \n",
       "          19                                      15.372857   \n",
       "          20                                      16.848571   \n",
       "          21                                      16.672857   \n",
       "          22                                      17.210000   \n",
       "\n",
       "                      reanalysis_tdtr_k  station_avg_temp_c  \\\n",
       "city year weekofyear                                          \n",
       "sj   1990 18                   2.628571           25.442857   \n",
       "          19                   2.371429           26.714286   \n",
       "          20                   2.300000           26.714286   \n",
       "          21                   2.428571           27.471429   \n",
       "          22                   3.014286           28.942857   \n",
       "\n",
       "                      station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "city year weekofyear                                                \n",
       "sj   1990 18                         6.900000                29.4   \n",
       "          19                         6.371429                31.7   \n",
       "          20                         6.485714                32.2   \n",
       "          21                         6.771429                33.3   \n",
       "          22                         9.371429                35.0   \n",
       "\n",
       "                      station_min_temp_c  station_precip_mm  \\\n",
       "city year weekofyear                                          \n",
       "sj   1990 18                        20.0               16.0   \n",
       "          19                        22.2                8.6   \n",
       "          20                        22.8               41.4   \n",
       "          21                        23.3                4.0   \n",
       "          22                        23.9                5.8   \n",
       "\n",
       "                      rainingday_for_week_before  \n",
       "city year weekofyear                              \n",
       "sj   1990 18                                 1.0  \n",
       "          19                                 2.0  \n",
       "          20                                 4.0  \n",
       "          21                                 5.0  \n",
       "          22                                 0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "# print(train_features.info())\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sj</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1990</th>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      total_cases\n",
       "city year weekofyear             \n",
       "sj   1990 18                    4\n",
       "          19                    5\n",
       "          20                    4\n",
       "          21                    3\n",
       "          22                    6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "# print(train_labels.info())\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 觀察原始資料\n",
    "# 將前三欄變成索引\n",
    "# sj_rainingday_for_week = pd.read_csv('sj_rainingday_for_week.csv',index_col=[0,1,2])\n",
    "# sj_rainingday_for_week.head()\n",
    "# sj_rainingday_for_week.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sj_rainingday_for_week.head()\n",
    "# sj_rainingday_for_week['Month']\n",
    "# sj_rainingday_for_week['Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?:查看缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 有缺失值的特徵\n",
    "# print(data.isnull().any().sum(), ' / ', len(data.columns))\n",
    "\n",
    "# # 有缺失值的資料筆數(因為有index及total_cases 所以全部皆有)\n",
    "# print(data.isnull().any(axis=1).sum(), ' / ', len(data))\n",
    "\n",
    "# # 觀察缺失比例\n",
    "# total= data.isnull().sum().sort_values(ascending=False)\n",
    "# percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total, percent], axis=1, keys=['Total','Lost Percent'])\n",
    "# print(data.info())\n",
    "# missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聖胡安(San Juan)\n",
    "位於北美洲加勒比海，為美國自治領地波多黎各的首府和最大城市，該城人口為433,733，是美國管轄的第42大城市。聖胡安是波多黎各最重要的海港以及製造業、金融、文化和旅遊中心。聖胡安都會區的人口約為200萬，占波多黎各全島人口的一半。聖胡安屬於熱帶海洋性氣候，降雨與日照高，雨季在7月至12月。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![聖胡安 (波多黎各)](imgs/San_Juan6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 伊基托斯(Iquitos)\n",
    "位於南美洲，為秘魯亞馬遜叢林地區最大城市，人口約40萬人，為洛雷托大區省會。伊基托斯位於亞馬遜河岸邊，無公路或鐵路與外界連接，對外交通完全依靠航空和亞馬遜河航運。雖然離亞馬遜河河口有3700公里遠，但是小型海輪還是可以溯流而上抵達伊基托斯，使得該地成為世界上距離海岸最遠的海港。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![伊基托斯 (秘魯)](imgs/Iquitos.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 22)\n",
      "(936, 1)\n",
      "(520, 22)\n",
      "(520, 1)\n"
     ]
    }
   ],
   "source": [
    "#位於北美與南美的兩個城市應該分開來train\n",
    "sj_train_features = train_features.loc['sj']\n",
    "sj_train_labels = train_labels.loc['sj']\n",
    "print(sj_train_features.shape)\n",
    "print(sj_train_labels.shape)\n",
    "\n",
    "iq_train_features = train_features.loc['iq']\n",
    "iq_train_labels = train_labels.loc['iq']\n",
    "print(iq_train_features.shape)\n",
    "print(iq_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 發現1991年及1994年的 39~49週出現極端值\n",
    "# sj_train_labels_90_94 = train_labels.loc['sj'].query('1990 <= year <= 1994')\n",
    "# sj_train_labels_90_94__39_49 = sj_train_labels_90_94.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_90_94__39_49\n",
    "\n",
    "# sj_train_labels_95_99 = train_labels.loc['sj'].query('1995 <= year <= 1999')\n",
    "# sj_train_labels_95_99__39_49 = sj_train_labels_95_99.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_95_99__39_49\n",
    "\n",
    "# sj_train_labels_00_04 = train_labels.loc['sj'].query('2000 <= year <= 2004')\n",
    "# sj_train_labels_00_04__39_49 = sj_train_labels_00_04.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_00_04__39_49\n",
    "\n",
    "# sj_train_labels_05_07 = train_labels.loc['sj'].query('2005 <= year <= 2007')\n",
    "# sj_train_labels_05_07__39_49 = sj_train_labels_05_07.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_05_07__39_49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除'week_start_date', 每周的起始日似乎較無意義\n",
    "sj_train_features = sj_train_features.drop('week_start_date', axis=1)\n",
    "iq_train_features = iq_train_features.drop('week_start_date', axis=1)\n",
    "# sj_train_features\n",
    "#iq_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### 產生新欄位,上週的資料 ###########################\n",
    "# 產生'reanalysis_specific_humidity_g_per_kg_before'欄位   (平均露點溫度)\n",
    "sj_train_features['reanalysis_specific_humidity_g_per_kg_before'] = sj_train_features['reanalysis_specific_humidity_g_per_kg']\n",
    "sj_train_features.reanalysis_specific_humidity_g_per_kg_before = sj_train_features.reanalysis_specific_humidity_g_per_kg.shift(1)\n",
    "# print(sj_train_features.reanalysis_specific_humidity_g_per_kg_before)\n",
    "\n",
    "iq_train_features['reanalysis_specific_humidity_g_per_kg_before'] = iq_train_features['reanalysis_specific_humidity_g_per_kg']\n",
    "iq_train_features.reanalysis_specific_humidity_g_per_kg_before = iq_train_features.reanalysis_specific_humidity_g_per_kg.shift(1)\n",
    "# print(iq_train_features.reanalysis_specific_humidity_g_per_kg_before)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (平均露點溫度)\n",
    "sj_train_features['reanalysis_dew_point_temp_k_before'] = sj_train_features['reanalysis_dew_point_temp_k']\n",
    "sj_train_features.reanalysis_dew_point_temp_k_before = sj_train_features.reanalysis_dew_point_temp_k.shift(1)\n",
    "iq_train_features['reanalysis_dew_point_temp_k_before'] = iq_train_features['reanalysis_dew_point_temp_k']\n",
    "iq_train_features.reanalysis_dew_point_temp_k_before = iq_train_features.reanalysis_dew_point_temp_k.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (最低氣溫)\n",
    "sj_train_features['reanalysis_min_air_temp_k_before'] = sj_train_features['reanalysis_min_air_temp_k']\n",
    "sj_train_features.reanalysis_min_air_temp_k_before = sj_train_features.reanalysis_min_air_temp_k.shift(1)\n",
    "iq_train_features['reanalysis_min_air_temp_k_before'] = iq_train_features['reanalysis_min_air_temp_k']\n",
    "iq_train_features.reanalysis_min_air_temp_k_before = iq_train_features.reanalysis_min_air_temp_k.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (最低溫度(測站每日))\n",
    "sj_train_features['station_min_temp_c_before'] = sj_train_features['station_min_temp_c']\n",
    "sj_train_features.station_min_temp_c_before = sj_train_features.station_min_temp_c.shift(1)\n",
    "iq_train_features['station_min_temp_c_before'] = iq_train_features['station_min_temp_c']\n",
    "iq_train_features.station_min_temp_c_before = iq_train_features.station_min_temp_c.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (平均溫度(測站每日))\n",
    "sj_train_features['station_avg_temp_c_before'] = sj_train_features['station_avg_temp_c']\n",
    "sj_train_features.station_avg_temp_c_before = sj_train_features.station_avg_temp_c.shift(1)\n",
    "iq_train_features['station_avg_temp_c_before'] = iq_train_features['station_avg_temp_c']\n",
    "iq_train_features.station_avg_temp_c_before = iq_train_features.station_avg_temp_c.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (平均氣溫(Mean))\n",
    "sj_train_features['reanalysis_air_temp_k_before'] = sj_train_features['reanalysis_air_temp_k']\n",
    "sj_train_features.reanalysis_air_temp_k_before = sj_train_features.reanalysis_air_temp_k.shift(1)\n",
    "iq_train_features['reanalysis_air_temp_k_before'] = iq_train_features['reanalysis_air_temp_k']\n",
    "iq_train_features.reanalysis_air_temp_k_before = iq_train_features.reanalysis_air_temp_k.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將數值差距較大的資料分群  # 沒啥用的感覺?!\n",
    "# sj_train_features['reanalysis_sat_precip_amt_mm'].describe()\n",
    "# def disavg(x):\n",
    "#     if x >= 52.18: \n",
    "#         return 2\n",
    "#     elif x >= 20.8:\n",
    "#         return 1\n",
    "# #     elif x >= 30:\n",
    "# #         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# sj_train_features['reanalysis_sat_precip_amt_mm_groupby'] = sj_train_features['reanalysis_sat_precip_amt_mm'].apply(disavg)\n",
    "# sj_train_features.head()\n",
    "\n",
    "sj_train_features['reanalysis_sat_precip_amt_mm'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.3269 → 25.3245\n",
    "# 異常值處理(離群點)   # 好像不是用dropna?!\n",
    "a = sj_train_features['reanalysis_sat_precip_amt_mm'] \n",
    "sj_train_features['reanalysis_sat_precip_amt_mm_lll'] = a - (a.std() * 3) ###### 將原始數據-3個標準差,取到極端值(回傳正數) ######\n",
    "mask = sj_train_features['reanalysis_sat_precip_amt_mm_lll'] > 0     # 透過>0取到布林值\n",
    "sj_train_features = sj_train_features[~mask]                         # 刪除整個row\n",
    "### sj_train_features['reanalysis_sat_precip_amt_mm'] = sj_train_features.reanalysis_sat_precip_amt_mm.[~mask]\n",
    "# sj_train_features\n",
    "\n",
    "# 原本927rows 刪完之後剩下906rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 透過 describe() 來檢查有哪些欄位可能有離群值\n",
    "sj_train_features['reanalysis_sat_precip_amt_mm'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填補缺失值\n",
    "sj_train_features.fillna(method='bfill', inplace=True)\n",
    "iq_train_features.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聖胡安(San Juan):\n",
      "病例平均數:  34.18055555555556\n",
      "病例變異數: 2640.045439691045\n",
      "\n",
      "伊基托斯(Iquitos):\n",
      "病例平均數:  7.565384615384615\n",
      "病例變異數: 115.8955239365642\n"
     ]
    }
   ],
   "source": [
    "# 觀察'total_cases'\n",
    "print('聖胡安(San Juan):')\n",
    "print('病例平均數: ', sj_train_labels.mean()[0])\n",
    "print('病例變異數:', sj_train_labels.var()[0])\n",
    "\n",
    "print('\\n伊基托斯(Iquitos):')\n",
    "print('病例平均數: ', iq_train_labels.mean()[0])\n",
    "print('病例變異數:', iq_train_labels.var()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.相關分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將label併到feature\n",
    "sj_train_features['total_cases'] = sj_train_labels.total_cases\n",
    "iq_train_features['total_cases'] = iq_train_labels.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算所有欄位(包含feature跟label)的相關係數\n",
    "sj_correlations = sj_train_features.corr()\n",
    "iq_correlations = iq_train_features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases                                     1.000000\n",
       "reanalysis_specific_humidity_g_per_kg_before    0.231365\n",
       "reanalysis_dew_point_temp_k_before              0.227624\n",
       "station_avg_temp_c_before                       0.224415\n",
       "station_min_temp_c_before                       0.214678\n",
       "reanalysis_min_air_temp_k_before                0.211575\n",
       "reanalysis_specific_humidity_g_per_kg           0.211571\n",
       "reanalysis_dew_point_temp_k                     0.207452\n",
       "reanalysis_air_temp_k_before                    0.204738\n",
       "station_avg_temp_c                              0.197190\n",
       "reanalysis_max_air_temp_k                       0.194062\n",
       "station_max_temp_c                              0.192725\n",
       "reanalysis_min_air_temp_k                       0.187733\n",
       "rainingday_for_week_before                      0.181545\n",
       "reanalysis_air_temp_k                           0.180772\n",
       "station_min_temp_c                              0.178157\n",
       "reanalysis_avg_temp_k                           0.173901\n",
       "ndvi_ne                                         0.170266\n",
       "reanalysis_relative_humidity_percent            0.156554\n",
       "reanalysis_precip_amt_kg_per_m2                 0.119413\n",
       "reanalysis_sat_precip_amt_mm_lll                0.092848\n",
       "reanalysis_sat_precip_amt_mm                    0.092848\n",
       "precipitation_amt_mm                            0.092848\n",
       "station_precip_mm                               0.072419\n",
       "ndvi_se                                         0.059708\n",
       "ndvi_sw                                         0.045523\n",
       "station_diur_temp_rng_c                         0.035389\n",
       "ndvi_nw                                         0.031361\n",
       "reanalysis_tdtr_k                              -0.067915\n",
       "Name: total_cases, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 聖胡安(San Juan)\n",
    "sj_correlations = sj_train_features.corr()\n",
    "sj_correlations.loc['total_cases'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases                                     1.000000\n",
       "reanalysis_specific_humidity_g_per_kg           0.235131\n",
       "reanalysis_dew_point_temp_k                     0.229138\n",
       "reanalysis_specific_humidity_g_per_kg_before    0.225773\n",
       "reanalysis_dew_point_temp_k_before              0.220560\n",
       "reanalysis_min_air_temp_k                       0.212263\n",
       "station_min_temp_c_before                       0.210040\n",
       "station_min_temp_c                              0.209195\n",
       "reanalysis_min_air_temp_k_before                0.188151\n",
       "station_avg_temp_c_before                       0.153970\n",
       "station_avg_temp_c                              0.151265\n",
       "reanalysis_relative_humidity_percent            0.129852\n",
       "reanalysis_precip_amt_kg_per_m2                 0.101464\n",
       "reanalysis_air_temp_k_before                    0.101098\n",
       "reanalysis_air_temp_k                           0.095680\n",
       "precipitation_amt_mm                            0.091580\n",
       "reanalysis_sat_precip_amt_mm                    0.091580\n",
       "reanalysis_avg_temp_k                           0.078724\n",
       "station_max_temp_c                              0.072299\n",
       "station_precip_mm                               0.043622\n",
       "ndvi_sw                                         0.034188\n",
       "ndvi_ne                                         0.021826\n",
       "ndvi_nw                                        -0.009362\n",
       "ndvi_se                                        -0.040076\n",
       "station_diur_temp_rng_c                        -0.051455\n",
       "reanalysis_max_air_temp_k                      -0.054964\n",
       "reanalysis_tdtr_k                              -0.133338\n",
       "rainingday_for_week_before                           NaN\n",
       "Name: total_cases, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 伊基托斯(Iquitos)\n",
    "iq_correlations = iq_train_features.corr()\n",
    "iq_correlations.loc['total_cases'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.產生Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data function -San Juan\n",
    "def preprocess_data_sj(data_path, labels_path=None):\n",
    "    #1.讀取feature 設索引\n",
    "    \n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "        \n",
    "    df['reanalysis_specific_humidity_g_per_kg_before'] = df['reanalysis_specific_humidity_g_per_kg']\n",
    "    df.reanalysis_specific_humidity_g_per_kg_before = df.reanalysis_specific_humidity_g_per_kg.shift(1)  \n",
    "    df['reanalysis_dew_point_temp_k_before'] = df['reanalysis_dew_point_temp_k']\n",
    "    df.reanalysis_dew_point_temp_k_before = df.reanalysis_dew_point_temp_k.shift(1) \n",
    "    df['reanalysis_air_temp_k_before'] = df['reanalysis_air_temp_k']\n",
    "    df.reanalysis_air_temp_k_before = df.reanalysis_air_temp_k.shift(1)  \n",
    "    df['reanalysis_min_air_temp_k_before'] = df['reanalysis_min_air_temp_k']\n",
    "    df.reanalysis_min_air_temp_k_before = df.reanalysis_min_air_temp_k.shift(1)  \n",
    "    df['station_avg_temp_c_before'] = df['station_avg_temp_c']\n",
    "    df.station_avg_temp_c_before = df.station_avg_temp_c.shift(1) \n",
    "    df['station_min_temp_c_before'] = df['station_min_temp_c']\n",
    "    df.station_min_temp_c_before = df.station_min_temp_c.shift(1)  \n",
    "    df['reanalysis_max_air_temp_k_before'] = df['reanalysis_max_air_temp_k']\n",
    "    df.reanalysis_max_air_temp_k_before = df.reanalysis_max_air_temp_k.shift(1)\n",
    "    \n",
    " # 將所有欄位都新增上週資料,取相關係數0.2以上且不重複\n",
    "    features = [\n",
    "#                  'reanalysis_specific_humidity_g_per_kg', \n",
    "#                  'reanalysis_dew_point_temp_k', \n",
    "#                  'station_avg_temp_c', \n",
    "#                  'reanalysis_max_air_temp_k'\n",
    "                \n",
    "#                 \"reanalysis_air_temp_k_before\",\n",
    "#                 \"reanalysis_specific_humidity_g_per_kg\",\n",
    "#                 \"station_min_temp_c_before\",\n",
    "#                 \"reanalysis_air_temp_k_before\",\n",
    "#                 \"station_min_temp_c_before\",\n",
    "                \"reanalysis_min_air_temp_k_before\",\n",
    "                \"reanalysis_max_air_temp_k_before\",\n",
    "                \"station_avg_temp_c_before\",\n",
    "                \"reanalysis_dew_point_temp_k_before\",\n",
    "                \"reanalysis_specific_humidity_g_per_kg_before\"\n",
    "               ]\n",
    "    df = df[features]\n",
    "    \n",
    "    #3.填補缺失值\n",
    "#     df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "\n",
    "    #4.讀取label 設索引 \n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    #5.分城市 取 San Juan\n",
    "    sj = df.loc['sj']\n",
    "    \n",
    "    return sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data function -Iquitos\n",
    "def preprocess_data_iq(data_path, labels_path=None):\n",
    "\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "    \n",
    "    df['reanalysis_specific_humidity_g_per_kg_before'] = df['reanalysis_specific_humidity_g_per_kg']\n",
    "    df.reanalysis_specific_humidity_g_per_kg_before = df.reanalysis_specific_humidity_g_per_kg.shift(1)  \n",
    "    df['reanalysis_dew_point_temp_k_before'] = df['reanalysis_dew_point_temp_k']\n",
    "    df.reanalysis_dew_point_temp_k_before = df.reanalysis_dew_point_temp_k.shift(1) \n",
    "    df['reanalysis_air_temp_k_before'] = df['reanalysis_air_temp_k']\n",
    "    df.reanalysis_air_temp_k_before = df.reanalysis_air_temp_k.shift(1)  \n",
    "    df['reanalysis_min_air_temp_k_before'] = df['reanalysis_min_air_temp_k']\n",
    "    df.reanalysis_min_air_temp_k_before = df.reanalysis_min_air_temp_k.shift(1)  \n",
    "    df['station_avg_temp_c_before'] = df['station_avg_temp_c']\n",
    "    df.station_avg_temp_c_before = df.station_avg_temp_c.shift(1) \n",
    "    df['station_min_temp_c_before'] = df['station_min_temp_c']\n",
    "    df.station_min_temp_c_before = df.station_min_temp_c.shift(1)  \n",
    "    df['reanalysis_max_air_temp_k_before'] = df['reanalysis_max_air_temp_k']\n",
    "    df.reanalysis_max_air_temp_k_before = df.reanalysis_max_air_temp_k.shift(1)\n",
    "    \n",
    "# 將所有欄位都新增上週資料,取相關係數0.2以上且不重複\n",
    "    features = [\n",
    "#                  'reanalysis_specific_humidity_g_per_kg', \n",
    "#                  'reanalysis_dew_point_temp_k', \n",
    "#                  'reanalysis_min_air_temp_k', \n",
    "#                  'station_min_temp_c'\n",
    "        \n",
    "#                 \"station_min_temp_c\",\n",
    "#                 \"station_min_temp_c_before\",\n",
    "#                 \"reanalysis_min_air_temp_k\",\n",
    "                \"station_min_temp_c_before\",\n",
    "                \"reanalysis_min_air_temp_k\",\n",
    "                \"reanalysis_dew_point_temp_k\",\n",
    "                \"reanalysis_specific_humidity_g_per_kg\"\n",
    "\n",
    "               ]\n",
    "    df = df[features]\n",
    "    \n",
    "\n",
    "#     df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "  \n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    iq = df.loc['iq']\n",
    "    \n",
    "    return iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 呼叫function 建立training data\n",
    "sj_train = preprocess_data_sj('dengue_features_train.csv',labels_path=\"dengue_labels_train.csv\")\n",
    "iq_train = preprocess_data_iq('dengue_features_train.csv',labels_path=\"dengue_labels_train.csv\")\n",
    "\n",
    "# sj_train = sj_train.query('year != 1991')\n",
    "# sj_train = sj_train.query('year != 1991').query('year != 1994')\n",
    "# sj_train = sj_train.query('weekofyear != 49')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sj_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 去除'total_cases'outlier\n",
    "# def outlierout(train):\n",
    "#     train = train[np.abs(train[\"total_cases\"]-train[\"total_cases\"].mean())<=(9*train[\"total_cases\"].std())] \n",
    "#     return train\n",
    "# # outlierout(sj_train).head()\n",
    "# sj_train = outlierout(sj_train)\n",
    "# # outlierout(iq_train).head()\n",
    "# iq_train = outlierout(iq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reanalysis_min_air_temp_k_before</th>\n",
       "      <th>reanalysis_max_air_temp_k_before</th>\n",
       "      <th>station_avg_temp_c_before</th>\n",
       "      <th>reanalysis_dew_point_temp_k_before</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg_before</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>936.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>936.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>297.296581</td>\n",
       "      <td>301.388675</td>\n",
       "      <td>26.994979</td>\n",
       "      <td>295.100285</td>\n",
       "      <td>16.543204</td>\n",
       "      <td>34.180556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.292930</td>\n",
       "      <td>1.261762</td>\n",
       "      <td>1.418055</td>\n",
       "      <td>1.571989</td>\n",
       "      <td>1.562609</td>\n",
       "      <td>51.381372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>292.600000</td>\n",
       "      <td>297.800000</td>\n",
       "      <td>22.842857</td>\n",
       "      <td>289.642857</td>\n",
       "      <td>11.715714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>296.300000</td>\n",
       "      <td>300.400000</td>\n",
       "      <td>25.810714</td>\n",
       "      <td>293.832857</td>\n",
       "      <td>15.225714</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>297.500000</td>\n",
       "      <td>301.500000</td>\n",
       "      <td>27.214286</td>\n",
       "      <td>295.447143</td>\n",
       "      <td>16.832143</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>298.400000</td>\n",
       "      <td>302.400000</td>\n",
       "      <td>28.175000</td>\n",
       "      <td>296.415714</td>\n",
       "      <td>17.854286</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299.900000</td>\n",
       "      <td>304.300000</td>\n",
       "      <td>30.071429</td>\n",
       "      <td>297.795714</td>\n",
       "      <td>19.440000</td>\n",
       "      <td>461.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reanalysis_min_air_temp_k_before  reanalysis_max_air_temp_k_before  \\\n",
       "count                        936.000000                        936.000000   \n",
       "mean                         297.296581                        301.388675   \n",
       "std                            1.292930                          1.261762   \n",
       "min                          292.600000                        297.800000   \n",
       "25%                          296.300000                        300.400000   \n",
       "50%                          297.500000                        301.500000   \n",
       "75%                          298.400000                        302.400000   \n",
       "max                          299.900000                        304.300000   \n",
       "\n",
       "       station_avg_temp_c_before  reanalysis_dew_point_temp_k_before  \\\n",
       "count                 936.000000                          936.000000   \n",
       "mean                   26.994979                          295.100285   \n",
       "std                     1.418055                            1.571989   \n",
       "min                    22.842857                          289.642857   \n",
       "25%                    25.810714                          293.832857   \n",
       "50%                    27.214286                          295.447143   \n",
       "75%                    28.175000                          296.415714   \n",
       "max                    30.071429                          297.795714   \n",
       "\n",
       "       reanalysis_specific_humidity_g_per_kg_before  total_cases  \n",
       "count                                    936.000000   936.000000  \n",
       "mean                                      16.543204    34.180556  \n",
       "std                                        1.562609    51.381372  \n",
       "min                                       11.715714     0.000000  \n",
       "25%                                       15.225714     9.000000  \n",
       "50%                                       16.832143    19.000000  \n",
       "75%                                       17.854286    37.000000  \n",
       "max                                       19.440000   461.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看San Juan數值資料\n",
    "sj_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_min_temp_c_before</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>520.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.203077</td>\n",
       "      <td>292.874231</td>\n",
       "      <td>295.498159</td>\n",
       "      <td>17.101552</td>\n",
       "      <td>7.565385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.277020</td>\n",
       "      <td>1.660301</td>\n",
       "      <td>1.415423</td>\n",
       "      <td>1.444031</td>\n",
       "      <td>10.765478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.700000</td>\n",
       "      <td>286.900000</td>\n",
       "      <td>290.088571</td>\n",
       "      <td>12.111429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.600000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>294.593929</td>\n",
       "      <td>16.121429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>293.100000</td>\n",
       "      <td>295.862857</td>\n",
       "      <td>17.435000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>294.200000</td>\n",
       "      <td>296.560000</td>\n",
       "      <td>18.194643</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.200000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>298.450000</td>\n",
       "      <td>20.461429</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_min_temp_c_before  reanalysis_min_air_temp_k  \\\n",
       "count                 520.000000                 520.000000   \n",
       "mean                   21.203077                 292.874231   \n",
       "std                     1.277020                   1.660301   \n",
       "min                    14.700000                 286.900000   \n",
       "25%                    20.600000                 292.000000   \n",
       "50%                    21.350000                 293.100000   \n",
       "75%                    22.000000                 294.200000   \n",
       "max                    24.200000                 296.000000   \n",
       "\n",
       "       reanalysis_dew_point_temp_k  reanalysis_specific_humidity_g_per_kg  \\\n",
       "count                   520.000000                             520.000000   \n",
       "mean                    295.498159                              17.101552   \n",
       "std                       1.415423                               1.444031   \n",
       "min                     290.088571                              12.111429   \n",
       "25%                     294.593929                              16.121429   \n",
       "50%                     295.862857                              17.435000   \n",
       "75%                     296.560000                              18.194643   \n",
       "max                     298.450000                              20.461429   \n",
       "\n",
       "       total_cases  \n",
       "count   520.000000  \n",
       "mean      7.565385  \n",
       "std      10.765478  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       5.000000  \n",
       "75%       9.000000  \n",
       "max     116.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看Iquitos數值資料\n",
    "iq_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sj_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iq_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.資料分割 > 建模 > 訓練 > 評估 > 預測 > 輸出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice1 :SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=31)\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "\n",
    "# from sklearn import svm, grid_search\n",
    "# def svc_param_selection(X, y, nfolds):\n",
    "#     Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "#     gammas = [0.001, 0.01, 0.1, 1]\n",
    "#     param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "#     grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "#     grid_search.fit(X, y)\n",
    "#     grid_search.best_params_\n",
    "#     return grid_search.best_params_\n",
    "\n",
    "# print(svc_param_selection(X_train_sj_std, y_train_sj, 10))\n",
    "\n",
    "\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # clf_sj = SVR(C=0.001,gamma=0.1)\n",
    "# clf_sj = SVR(kernel='poly', \n",
    "#             degree=5, \n",
    "#             gamma='auto',\n",
    "#             coef0=0.0, \n",
    "#             tol=0.0001, \n",
    "#             C=2.0, \n",
    "#             epsilon=0.1, \n",
    "#             shrinking=True, \n",
    "#             cache_size=200, \n",
    "#             verbose=False, \n",
    "#             max_iter=-1)\n",
    "\n",
    "\n",
    "# clf_sj.fit(X_train_sj_std, y_train_sj)\n",
    "# y_pred_sj = clf_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(clf_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "\n",
    "# ###########################################################################################################################\n",
    "\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = clf_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice2 :Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## sj Lasso\n",
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "# #25.4399\n",
    "# # lasso_sj = Lasso(alpha=0.008, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# #25.4207\n",
    "# # lasso_sj = Lasso(alpha=0.0008, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# # #25.3606\n",
    "# # lasso_sj = Lasso(alpha=0.0008, copy_X=True, fit_intercept=True, max_iter=2000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "\n",
    "# lasso_sj = Lasso(alpha=0.00008, copy_X=True, fit_intercept=True, max_iter=3000,\n",
    "#                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "#                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=31)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# lasso_sj.fit(X_train_sj_std, y_train_sj)\n",
    "# y_pred_sj = lasso_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(lasso_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# ########################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = lasso_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iq lasso\n",
    "# from sklearn.linear_model import Lasso\n",
    "# # lasso_iq = Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# lasso_iq = Lasso(alpha=0.00008, copy_X=True, fit_intercept=True, max_iter=3000,\n",
    "#                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "#                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# X = iq_train.iloc[:,0:-1].values\n",
    "# y = iq_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_iq,X_test_iq,y_train_iq,y_test_iq = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=209)\n",
    "# sc = StandardScaler()\n",
    "# X_train_iq_std = sc.fit_transform(X_train_iq)\n",
    "# X_test_iq_std = sc.transform(X_test_iq)\n",
    "\n",
    "# lasso_iq.fit(X_train_iq_std, y_train_iq)\n",
    "# y_pred_iq = lasso_iq.predict(X_test_iq_std)\n",
    "# print(\"Score:\"+str(lasso_iq.score(X_test_iq_std, y_test_iq)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_iq, y_pred_iq)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_iq, y_pred_iq))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_iq, y_pred_iq)))\n",
    "# #######################################################################\n",
    "# iq_test = preprocess_data_iq('dengue_features_test.csv')\n",
    "\n",
    "# X2 = iq_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_iq = lasso_iq.predict(X2_std).astype(int)\n",
    "# print(total_cases_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice3 :Bagging(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                           test_size=0.3,\n",
    "#                                                                           random_state=31)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# ensemble = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
    "#                             n_estimators=7,\n",
    "#                             max_samples=1.0,\n",
    "#                             max_features=1.0,\n",
    "# #                             bootstrap=True,\n",
    "# #                             oob_score=False,\n",
    "#                             bootstrap_features=False,\n",
    "#                             n_jobs=4,\n",
    "#                             verbose=0,\n",
    "#                             random_state=31).fit(X_train_sj_std, y_train_sj)\n",
    "\n",
    "# ensemble.fit(X_train_sj_std,y_train_sj) \n",
    "# y_pred_sj = ensemble.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(ensemble.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# # #######################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = ensemble.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice4 :Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sj Ridge\n",
    "X = sj_train.iloc[:,0:-1].values\n",
    "y = sj_train.iloc[:,-1].values\n",
    "\n",
    "X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,test_size=0.3,random_state=31)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgecv_sj = RidgeCV(alphas=[0.0001, 0.0001, 0.01, 0.1, 0.15, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.17, 0.18, 0.19, 0.2, 0.25, 0.3])\n",
    "ridgecv_sj.fit(X_train_sj_std, y_train_sj)\n",
    "ridgecv_sj.alpha_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.003895224622513682\n",
      "MAE:25.444610438628644\n",
      "MSE: 2170.659410799321\n",
      "RMSE: 46.590336023679\n",
      "[27 27 25 35 33 32 33 37 47 44 43 36 42 45 44 53 55 54 59 68 64 56 52 58\n",
      " 47 48 43 37 47 46 39 30 19 17 21 19 20 20 18 20 21 19 16 16 14 16 19 11\n",
      " 17 15 15 18 21 22 18 24 22 42 37 35 40 41 46 47 50 50 51 47 48 50 60 54\n",
      " 54 52 48 59 58 60 55 46 41 41 51 47 36 35 31 31 30 30 27 26 28 15 25 31\n",
      " 30 41 36 34 42 33 32 22 35 48 48 38 42 48 65 60 54 54 56 59 65 56 55 57\n",
      " 64 61 65 67 67 61 59 54 60 65 53 45 43 47 35 22 20 22 30 26 12  9 21 18\n",
      " 17 12 14 14 15  8 11 12  8 19 23 14 14 17 22 16 28 36 44 42 58 53 50 48\n",
      " 46 42 53 46 57 52 56 53 47 55 49 50 56 44 42 37 46 41 40 32 30 21 26 14\n",
      " 16 19 16 13  9  8 11 14 11 12 13 10 11 15 21 22 21 25 30 23 39 34 27 42\n",
      " 41 45 46 44 42 48 47 44 47 52 50 46 42 44 44 51 50 44 55 51 56 44 43 43\n",
      " 35 29 22 21 21 17 12 12 17 13 14 13 13 19 17 15 25 23 25 23]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#25.3317\n",
    "# ridge_sj = Ridge(alpha=0.0015)\n",
    "\n",
    "#25.3269\n",
    "ridge_sj = Ridge(alpha=0.00015)\n",
    "\n",
    "#25.3534\n",
    "# ridge_sj = Ridge(alpha=0.000015, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "#                  normalize=False, random_state=None, solver='sag', tol=0.001)\n",
    "\n",
    "ridge_sj.fit(X_train_sj_std,y_train_sj) \n",
    "y_pred_sj = ridge_sj.predict(X_test_sj_std)\n",
    "print(\"Score:\"+str(ridge_sj.score(X_test_sj_std, y_test_sj)))\n",
    "print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# #######################################################################\n",
    "sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "X2 = sj_test.values\n",
    "X2_std = sc.transform(X2)\n",
    "\n",
    "total_cases_sj = ridge_sj.predict(X2_std).astype(int)\n",
    "print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iq Ridge\n",
    "X = iq_train.iloc[:,0:-1].values\n",
    "y = iq_train.iloc[:,-1].values\n",
    "\n",
    "X_train_iq,X_test_iq,y_train_iq,y_test_iq = cross_validation.train_test_split(X,y,test_size=0.3,random_state=201)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_iq_std = sc.fit_transform(X_train_iq)\n",
    "X_test_iq_std = sc.transform(X_test_iq)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgecv_iq = RidgeCV(alphas=[0.0001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.4, 0.5, 1])\n",
    "ridgecv_iq.fit(X_train_iq_std, y_train_iq)\n",
    "ridgecv_iq.alpha_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.10705669836000033\n",
      "MAE:5.4545291214877825\n",
      "MSE: 55.0567646330876\n",
      "RMSE: 7.420024570922094\n",
      "[ 8  6  8  6 -3  1  6  3  6  6  6  6  7  3  7  6  7  8 12  8  8  9 10 11\n",
      " 10  8  7  9  9  8  6  7  7  9  9 10  8  9  9  9 10  7  8 10 11  5  7  9\n",
      "  4  3  4  2  3  3  2  3  4  5  4  4  5  0  1  7  6  8  8  8 11 10  7  9\n",
      " 10 10  9 11  9  9 11 10 10  9  6  8 11  9  8  7  7  7  7  8  6 10 11  9\n",
      " 10  6  5  6  6  7  4  1  4  3  3  5  1  0  3  1  2  4  4  4  5  6  4  8\n",
      "  9  9 10  9 12 13 13 11 12 11 10  8  7 11  9 12 10 11  9 10 12 13 12 10\n",
      "  9 11 10  4  5 10  7  7  8  5  5  5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#25.3317\n",
    "# ridge_iq = Ridge(alpha=0.27)\n",
    "\n",
    "#25.3269\n",
    "ridge_iq = Ridge(alpha=0.275)\n",
    "\n",
    "#25.3534\n",
    "# ridge_iq = Ridge(alpha=0.276, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "#                  normalize=False, random_state=None, solver='sag', tol=0.001)\n",
    "\n",
    "ridge_iq.fit(X_train_iq_std,y_train_iq) \n",
    "y_pred_iq = ridge_iq.predict(X_test_iq_std)\n",
    "print(\"Score:\"+str(ridge_iq.score(X_test_iq_std, y_test_iq)))\n",
    "print(\"MAE:\"+str(mean_absolute_error(y_test_iq, y_pred_iq)))\n",
    "print(\"MSE:\",metrics.mean_squared_error(y_test_iq, y_pred_iq))\n",
    "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_iq, y_pred_iq)))\n",
    "# #######################################################################\n",
    "iq_test = preprocess_data_iq('dengue_features_test.csv')\n",
    "\n",
    "X2 = iq_test.values\n",
    "X2_std = sc.transform(X2)\n",
    "\n",
    "total_cases_iq = ridge_iq.predict(X2_std).astype(int)\n",
    "print(total_cases_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice5 :Liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## model sj\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# regr_sj = linear_model.LinearRegression()\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=31)\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# regr_sj.fit(X_train_sj_std, y_train_sj)\n",
    "# y_pred_sj = regr_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(regr_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# #######################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = regr_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # model iq\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# regr_iq = linear_model.LinearRegression()\n",
    "\n",
    "# X = iq_train.iloc[:,0:-1].values\n",
    "# y = iq_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_iq,X_test_iq,y_train_iq,y_test_iq = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=201)\n",
    "# sc = StandardScaler()\n",
    "# X_train_iq_std = sc.fit_transform(X_train_iq)\n",
    "# X_test_iq_std = sc.transform(X_test_iq)\n",
    "\n",
    "# regr_iq.fit(X_train_iq_std, y_train_iq)\n",
    "# y_pred_iq = regr_iq.predict(X_test_iq_std)\n",
    "# print(\"Score:\"+str(regr_iq.score(X_test_iq_std, y_test_iq)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_iq, y_pred_iq)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_iq, y_pred_iq))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_iq, y_pred_iq)))\n",
    "# #######################################################################\n",
    "# iq_test = preprocess_data_iq('dengue_features_test.csv')\n",
    "\n",
    "# X2 = iq_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_iq = regr_iq.predict(X2_std).astype(int)\n",
    "# print(total_cases_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將預測結果 numpy轉pandas\n",
    "total_cases_sj =pd.DataFrame({\"total_cases\": total_cases_sj})\n",
    "total_cases_iq =pd.DataFrame({\"total_cases\": total_cases_iq})\n",
    "total_cases_all = pd.concat([total_cases_sj,total_cases_iq], axis=0).reset_index()    \n",
    "        \n",
    "#  讀取submission_format\n",
    "submission_format = pd.read_csv('submission_format.csv')\n",
    "submission_format = submission_format.drop(['total_cases'], axis=1)\n",
    "submission_format.head()  \n",
    "    \n",
    "# 合併submission_format及輸出結果\n",
    "submission = pd.concat([submission_format,total_cases_all['total_cases']], axis=1) \n",
    "submission  \n",
    "\n",
    "# 輸出csv檔\n",
    "submission.to_csv('test_mars_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
