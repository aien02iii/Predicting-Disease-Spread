{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DengAI: Predicting Disease Spread _ DRIVENDATA Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.引入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "from sklearn import cross_validation, tree, linear_model,metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor,XGBClassifier\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.觀察原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將前三欄變成索引\n",
    "train_features = pd.read_csv('dengue_features_train.csv',index_col=[0,1,2])\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv',index_col=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>rainingday_for_week_before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sj</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1990</th>\n",
       "      <th>18</th>\n",
       "      <td>1990/4/30</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>292.414286</td>\n",
       "      <td>299.8</td>\n",
       "      <td>...</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1990/5/7</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>293.951429</td>\n",
       "      <td>300.9</td>\n",
       "      <td>...</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1990/5/14</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>295.434286</td>\n",
       "      <td>300.5</td>\n",
       "      <td>...</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1990/5/21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>299.228571</td>\n",
       "      <td>295.310000</td>\n",
       "      <td>301.4</td>\n",
       "      <td>...</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1990/5/28</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>299.664286</td>\n",
       "      <td>295.821429</td>\n",
       "      <td>301.9</td>\n",
       "      <td>...</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     week_start_date   ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "city year weekofyear                                                           \n",
       "sj   1990 18               1990/4/30  0.122600  0.103725  0.198483  0.177617   \n",
       "          19                1990/5/7  0.169900  0.142175  0.162357  0.155486   \n",
       "          20               1990/5/14  0.032250  0.172967  0.157200  0.170843   \n",
       "          21               1990/5/21  0.128633  0.245067  0.227557  0.235886   \n",
       "          22               1990/5/28  0.196200  0.262200  0.251200  0.247340   \n",
       "\n",
       "                      precipitation_amt_mm  reanalysis_air_temp_k  \\\n",
       "city year weekofyear                                                \n",
       "sj   1990 18                         12.42             297.572857   \n",
       "          19                         22.82             298.211429   \n",
       "          20                         34.54             298.781429   \n",
       "          21                         15.36             298.987143   \n",
       "          22                          7.52             299.518571   \n",
       "\n",
       "                      reanalysis_avg_temp_k  reanalysis_dew_point_temp_k  \\\n",
       "city year weekofyear                                                       \n",
       "sj   1990 18                     297.742857                   292.414286   \n",
       "          19                     298.442857                   293.951429   \n",
       "          20                     298.878571                   295.434286   \n",
       "          21                     299.228571                   295.310000   \n",
       "          22                     299.664286                   295.821429   \n",
       "\n",
       "                      reanalysis_max_air_temp_k             ...              \\\n",
       "city year weekofyear                                        ...               \n",
       "sj   1990 18                              299.8             ...               \n",
       "          19                              300.9             ...               \n",
       "          20                              300.5             ...               \n",
       "          21                              301.4             ...               \n",
       "          22                              301.9             ...               \n",
       "\n",
       "                      reanalysis_relative_humidity_percent  \\\n",
       "city year weekofyear                                         \n",
       "sj   1990 18                                     73.365714   \n",
       "          19                                     77.368571   \n",
       "          20                                     82.052857   \n",
       "          21                                     80.337143   \n",
       "          22                                     80.460000   \n",
       "\n",
       "                      reanalysis_sat_precip_amt_mm  \\\n",
       "city year weekofyear                                 \n",
       "sj   1990 18                                 12.42   \n",
       "          19                                 22.82   \n",
       "          20                                 34.54   \n",
       "          21                                 15.36   \n",
       "          22                                  7.52   \n",
       "\n",
       "                      reanalysis_specific_humidity_g_per_kg  \\\n",
       "city year weekofyear                                          \n",
       "sj   1990 18                                      14.012857   \n",
       "          19                                      15.372857   \n",
       "          20                                      16.848571   \n",
       "          21                                      16.672857   \n",
       "          22                                      17.210000   \n",
       "\n",
       "                      reanalysis_tdtr_k  station_avg_temp_c  \\\n",
       "city year weekofyear                                          \n",
       "sj   1990 18                   2.628571           25.442857   \n",
       "          19                   2.371429           26.714286   \n",
       "          20                   2.300000           26.714286   \n",
       "          21                   2.428571           27.471429   \n",
       "          22                   3.014286           28.942857   \n",
       "\n",
       "                      station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "city year weekofyear                                                \n",
       "sj   1990 18                         6.900000                29.4   \n",
       "          19                         6.371429                31.7   \n",
       "          20                         6.485714                32.2   \n",
       "          21                         6.771429                33.3   \n",
       "          22                         9.371429                35.0   \n",
       "\n",
       "                      station_min_temp_c  station_precip_mm  \\\n",
       "city year weekofyear                                          \n",
       "sj   1990 18                        20.0               16.0   \n",
       "          19                        22.2                8.6   \n",
       "          20                        22.8               41.4   \n",
       "          21                        23.3                4.0   \n",
       "          22                        23.9                5.8   \n",
       "\n",
       "                      rainingday_for_week_before  \n",
       "city year weekofyear                              \n",
       "sj   1990 18                                 1.0  \n",
       "          19                                 2.0  \n",
       "          20                                 4.0  \n",
       "          21                                 5.0  \n",
       "          22                                 0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "# print(train_features.info())\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sj</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1990</th>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      total_cases\n",
       "city year weekofyear             \n",
       "sj   1990 18                    4\n",
       "          19                    5\n",
       "          20                    4\n",
       "          21                    3\n",
       "          22                    6"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "# print(train_labels.info())\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?:查看缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 有缺失值的特徵\n",
    "# print(data.isnull().any().sum(), ' / ', len(data.columns))\n",
    "\n",
    "# # 有缺失值的資料筆數(因為有index及total_cases 所以全部皆有)\n",
    "# print(data.isnull().any(axis=1).sum(), ' / ', len(data))\n",
    "\n",
    "# # 觀察缺失比例\n",
    "# total= data.isnull().sum().sort_values(ascending=False)\n",
    "# percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total, percent], axis=1, keys=['Total','Lost Percent'])\n",
    "# print(data.info())\n",
    "# missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聖胡安(San Juan)\n",
    "位於北美洲加勒比海，為美國自治領地波多黎各的首府和最大城市，該城人口為433,733，是美國管轄的第42大城市。聖胡安是波多黎各最重要的海港以及製造業、金融、文化和旅遊中心。聖胡安都會區的人口約為200萬，占波多黎各全島人口的一半。聖胡安屬於熱帶海洋性氣候，降雨與日照高，雨季在7月至12月。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![聖胡安 (波多黎各)](imgs/San_Juan6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 伊基托斯(Iquitos)\n",
    "位於南美洲，為秘魯亞馬遜叢林地區最大城市，人口約40萬人，為洛雷托大區省會。伊基托斯位於亞馬遜河岸邊，無公路或鐵路與外界連接，對外交通完全依靠航空和亞馬遜河航運。雖然離亞馬遜河河口有3700公里遠，但是小型海輪還是可以溯流而上抵達伊基托斯，使得該地成為世界上距離海岸最遠的海港。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![伊基托斯 (秘魯)](imgs/Iquitos.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 22)\n",
      "(936, 1)\n",
      "(520, 22)\n",
      "(520, 1)\n"
     ]
    }
   ],
   "source": [
    "#位於北美與南美的兩個城市應該分開來train\n",
    "sj_train_features = train_features.loc['sj']\n",
    "sj_train_labels = train_labels.loc['sj']\n",
    "print(sj_train_features.shape)\n",
    "print(sj_train_labels.shape)\n",
    "\n",
    "iq_train_features = train_features.loc['iq']\n",
    "iq_train_labels = train_labels.loc['iq']\n",
    "print(iq_train_features.shape)\n",
    "print(iq_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 發現1991年及1994年的 39~49週出現極端值\n",
    "# sj_train_labels_90_94 = train_labels.loc['sj'].query('1990 <= year <= 1994')\n",
    "# sj_train_labels_90_94__39_49 = sj_train_labels_90_94.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_90_94__39_49\n",
    "\n",
    "# sj_train_labels_95_99 = train_labels.loc['sj'].query('1995 <= year <= 1999')\n",
    "# sj_train_labels_95_99__39_49 = sj_train_labels_95_99.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_95_99__39_49\n",
    "\n",
    "# sj_train_labels_00_04 = train_labels.loc['sj'].query('2000 <= year <= 2004')\n",
    "# sj_train_labels_00_04__39_49 = sj_train_labels_00_04.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_00_04__39_49\n",
    "\n",
    "# sj_train_labels_05_07 = train_labels.loc['sj'].query('2005 <= year <= 2007')\n",
    "# sj_train_labels_05_07__39_49 = sj_train_labels_05_07.query('39 <= weekofyear <= 49')\n",
    "# sj_train_labels_05_07__39_49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除'week_start_date', 每周的起始日似乎較無意義\n",
    "sj_train_features = sj_train_features.drop('week_start_date', axis=1)\n",
    "iq_train_features = iq_train_features.drop('week_start_date', axis=1)\n",
    "# sj_train_features\n",
    "#iq_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### 產生新欄位,上週的資料 ###########################\n",
    "# 產生'reanalysis_specific_humidity_g_per_kg_before'欄位   (平均露點溫度)\n",
    "sj_train_features['reanalysis_specific_humidity_g_per_kg_before'] = sj_train_features['reanalysis_specific_humidity_g_per_kg']\n",
    "sj_train_features.reanalysis_specific_humidity_g_per_kg_before = sj_train_features.reanalysis_specific_humidity_g_per_kg.shift(1)\n",
    "# print(sj_train_features.reanalysis_specific_humidity_g_per_kg_before)\n",
    "\n",
    "iq_train_features['reanalysis_specific_humidity_g_per_kg_before'] = iq_train_features['reanalysis_specific_humidity_g_per_kg']\n",
    "iq_train_features.reanalysis_specific_humidity_g_per_kg_before = iq_train_features.reanalysis_specific_humidity_g_per_kg.shift(1)\n",
    "# print(iq_train_features.reanalysis_specific_humidity_g_per_kg_before)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (平均露點溫度)\n",
    "sj_train_features['reanalysis_dew_point_temp_k_before'] = sj_train_features['reanalysis_dew_point_temp_k']\n",
    "sj_train_features.reanalysis_dew_point_temp_k_before = sj_train_features.reanalysis_dew_point_temp_k.shift(1)\n",
    "iq_train_features['reanalysis_dew_point_temp_k_before'] = iq_train_features['reanalysis_dew_point_temp_k']\n",
    "iq_train_features.reanalysis_dew_point_temp_k_before = iq_train_features.reanalysis_dew_point_temp_k.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (最低氣溫)\n",
    "sj_train_features['reanalysis_min_air_temp_k_before'] = sj_train_features['reanalysis_min_air_temp_k']\n",
    "sj_train_features.reanalysis_min_air_temp_k_before = sj_train_features.reanalysis_min_air_temp_k.shift(1)\n",
    "iq_train_features['reanalysis_min_air_temp_k_before'] = iq_train_features['reanalysis_min_air_temp_k']\n",
    "iq_train_features.reanalysis_min_air_temp_k_before = iq_train_features.reanalysis_min_air_temp_k.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (最低溫度(測站每日))\n",
    "sj_train_features['station_min_temp_c_before'] = sj_train_features['station_min_temp_c']\n",
    "sj_train_features.station_min_temp_c_before = sj_train_features.station_min_temp_c.shift(1)\n",
    "iq_train_features['station_min_temp_c_before'] = iq_train_features['station_min_temp_c']\n",
    "iq_train_features.station_min_temp_c_before = iq_train_features.station_min_temp_c.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (平均溫度(測站每日))\n",
    "sj_train_features['station_avg_temp_c_before'] = sj_train_features['station_avg_temp_c']\n",
    "sj_train_features.station_avg_temp_c_before = sj_train_features.station_avg_temp_c.shift(1)\n",
    "iq_train_features['station_avg_temp_c_before'] = iq_train_features['station_avg_temp_c']\n",
    "iq_train_features.station_avg_temp_c_before = iq_train_features.station_avg_temp_c.shift(1)\n",
    "#####################################################################################################\n",
    "# 產生欄位   (平均氣溫(Mean))\n",
    "sj_train_features['reanalysis_air_temp_k_before'] = sj_train_features['reanalysis_air_temp_k']\n",
    "sj_train_features.reanalysis_air_temp_k_before = sj_train_features.reanalysis_air_temp_k.shift(1)\n",
    "iq_train_features['reanalysis_air_temp_k_before'] = iq_train_features['reanalysis_air_temp_k']\n",
    "iq_train_features.reanalysis_air_temp_k_before = iq_train_features.reanalysis_air_temp_k.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sj_train_features['reanalysis_min_air_temp_k'].count()   #936\n",
    "# # \n",
    "# # 異常值處理(離群點)   # 好像不是用dropna?!\n",
    "# a = sj_train_features['reanalysis_min_air_temp_k'] \n",
    "# sj_train_features['reanalysis_min_air_temp_k_lll'] = a - (a.std() * 3) ###### 將原始數據-3個標準差,取到極端值(回傳正數) ######\n",
    "# mask = sj_train_features['reanalysis_min_air_temp_k_lll'] > 0     # 透過>0取到布林值\n",
    "# sj_train_features = sj_train_features[~mask]                         # 刪除整個row\n",
    "# ### sj_train_features['reanalysis_sat_precip_amt_mm'] = sj_train_features.reanalysis_sat_precip_amt_mm.[~mask]\n",
    "# # sj_train_features\n",
    "\n",
    "# # 原本927rows 刪完之後剩下906rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sj_train_features['reanalysis_min_air_temp_k'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sj_train_features['reanalysis_min_air_temp_k'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填補缺失值\n",
    "sj_train_features.fillna(method='bfill', inplace=True)\n",
    "iq_train_features.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聖胡安(San Juan):\n",
      "病例平均數:  34.18055555555556\n",
      "病例變異數: 2640.045439691045\n",
      "\n",
      "伊基托斯(Iquitos):\n",
      "病例平均數:  7.565384615384615\n",
      "病例變異數: 115.8955239365642\n"
     ]
    }
   ],
   "source": [
    "# 觀察'total_cases'\n",
    "print('聖胡安(San Juan):')\n",
    "print('病例平均數: ', sj_train_labels.mean()[0])\n",
    "print('病例變異數:', sj_train_labels.var()[0])\n",
    "\n",
    "print('\\n伊基托斯(Iquitos):')\n",
    "print('病例平均數: ', iq_train_labels.mean()[0])\n",
    "print('病例變異數:', iq_train_labels.var()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.相關分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將label併到feature\n",
    "sj_train_features['total_cases'] = sj_train_labels.total_cases\n",
    "iq_train_features['total_cases'] = iq_train_labels.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算所有欄位(包含feature跟label)的相關係數\n",
    "sj_correlations = sj_train_features.corr()\n",
    "iq_correlations = iq_train_features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases                                     1.000000\n",
       "reanalysis_specific_humidity_g_per_kg_before    0.229576\n",
       "reanalysis_dew_point_temp_k_before              0.225888\n",
       "station_avg_temp_c_before                       0.220938\n",
       "reanalysis_min_air_temp_k_before                0.211635\n",
       "station_min_temp_c_before                       0.210622\n",
       "reanalysis_specific_humidity_g_per_kg           0.208066\n",
       "reanalysis_dew_point_temp_k                     0.204009\n",
       "reanalysis_air_temp_k_before                    0.203935\n",
       "station_avg_temp_c                              0.195358\n",
       "reanalysis_max_air_temp_k                       0.193595\n",
       "station_max_temp_c                              0.189083\n",
       "reanalysis_min_air_temp_k                       0.187383\n",
       "reanalysis_air_temp_k                           0.181042\n",
       "station_min_temp_c                              0.176109\n",
       "reanalysis_avg_temp_k                           0.174549\n",
       "ndvi_ne                                         0.174359\n",
       "rainingday_for_week_before                      0.172498\n",
       "reanalysis_relative_humidity_percent            0.145885\n",
       "reanalysis_precip_amt_kg_per_m2                 0.107250\n",
       "reanalysis_sat_precip_amt_mm                    0.063095\n",
       "precipitation_amt_mm                            0.063095\n",
       "ndvi_se                                         0.057941\n",
       "station_precip_mm                               0.052867\n",
       "ndvi_sw                                         0.044591\n",
       "station_diur_temp_rng_c                         0.035728\n",
       "ndvi_nw                                         0.031949\n",
       "reanalysis_tdtr_k                              -0.067273\n",
       "Name: total_cases, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 聖胡安(San Juan)\n",
    "sj_correlations = sj_train_features.corr()\n",
    "sj_correlations.loc['total_cases'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases                                     1.000000\n",
       "reanalysis_specific_humidity_g_per_kg           0.235131\n",
       "reanalysis_dew_point_temp_k                     0.229138\n",
       "reanalysis_specific_humidity_g_per_kg_before    0.225773\n",
       "reanalysis_dew_point_temp_k_before              0.220560\n",
       "reanalysis_min_air_temp_k                       0.212263\n",
       "station_min_temp_c_before                       0.210040\n",
       "station_min_temp_c                              0.209195\n",
       "reanalysis_min_air_temp_k_before                0.188151\n",
       "station_avg_temp_c_before                       0.153970\n",
       "station_avg_temp_c                              0.151265\n",
       "reanalysis_relative_humidity_percent            0.129852\n",
       "reanalysis_precip_amt_kg_per_m2                 0.101464\n",
       "reanalysis_air_temp_k_before                    0.101098\n",
       "reanalysis_air_temp_k                           0.095680\n",
       "precipitation_amt_mm                            0.091580\n",
       "reanalysis_sat_precip_amt_mm                    0.091580\n",
       "reanalysis_avg_temp_k                           0.078724\n",
       "station_max_temp_c                              0.072299\n",
       "station_precip_mm                               0.043622\n",
       "ndvi_sw                                         0.034188\n",
       "ndvi_ne                                         0.021826\n",
       "ndvi_nw                                        -0.009362\n",
       "ndvi_se                                        -0.040076\n",
       "station_diur_temp_rng_c                        -0.051455\n",
       "reanalysis_max_air_temp_k                      -0.054964\n",
       "reanalysis_tdtr_k                              -0.133338\n",
       "rainingday_for_week_before                           NaN\n",
       "Name: total_cases, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 伊基托斯(Iquitos)\n",
    "iq_correlations = iq_train_features.corr()\n",
    "iq_correlations.loc['total_cases'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.產生Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data function -San Juan\n",
    "def preprocess_data_sj(data_path, labels_path=None):\n",
    "    #1.讀取feature 設索引\n",
    "    \n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "        \n",
    "    df['reanalysis_specific_humidity_g_per_kg_before'] = df['reanalysis_specific_humidity_g_per_kg']\n",
    "    df.reanalysis_specific_humidity_g_per_kg_before = df.reanalysis_specific_humidity_g_per_kg.shift(1)  \n",
    "    df['reanalysis_dew_point_temp_k_before'] = df['reanalysis_dew_point_temp_k']\n",
    "    df.reanalysis_dew_point_temp_k_before = df.reanalysis_dew_point_temp_k.shift(1) \n",
    "    df['reanalysis_air_temp_k_before'] = df['reanalysis_air_temp_k']\n",
    "    df.reanalysis_air_temp_k_before = df.reanalysis_air_temp_k.shift(1)  \n",
    "    df['reanalysis_min_air_temp_k_before'] = df['reanalysis_min_air_temp_k']\n",
    "    df.reanalysis_min_air_temp_k_before = df.reanalysis_min_air_temp_k.shift(1)  \n",
    "    df['station_avg_temp_c_before'] = df['station_avg_temp_c']\n",
    "    df.station_avg_temp_c_before = df.station_avg_temp_c.shift(1) \n",
    "    df['station_min_temp_c_before'] = df['station_min_temp_c']\n",
    "    df.station_min_temp_c_before = df.station_min_temp_c.shift(1)  \n",
    "    df['reanalysis_max_air_temp_k_before'] = df['reanalysis_max_air_temp_k']\n",
    "    df.reanalysis_max_air_temp_k_before = df.reanalysis_max_air_temp_k.shift(1)\n",
    "    \n",
    " # 將所有欄位都新增上週資料,取相關係數0.2以上且不重複\n",
    "    features = [\n",
    "#                  'reanalysis_specific_humidity_g_per_kg', \n",
    "#                  'reanalysis_dew_point_temp_k', \n",
    "#                  'station_avg_temp_c', \n",
    "#                  'reanalysis_max_air_temp_k'\n",
    "                \n",
    "#                 \"reanalysis_air_temp_k_before\",\n",
    "#                 \"reanalysis_specific_humidity_g_per_kg\",\n",
    "#                 \"station_min_temp_c_before\",\n",
    "#                 \"reanalysis_air_temp_k_before\",\n",
    "#                 \"station_min_temp_c_before\",\n",
    "                \"reanalysis_min_air_temp_k_before\",\n",
    "                \"reanalysis_max_air_temp_k_before\",\n",
    "                \"station_avg_temp_c_before\",\n",
    "                \"reanalysis_dew_point_temp_k_before\",\n",
    "                \"reanalysis_specific_humidity_g_per_kg_before\"\n",
    "               ]\n",
    "    df = df[features]\n",
    "    \n",
    "    #3.填補缺失值\n",
    "#     df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "\n",
    "    #4.讀取label 設索引 \n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    #5.分城市 取 San Juan\n",
    "    sj = df.loc['sj']\n",
    "    \n",
    "    return sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data function -Iquitos\n",
    "def preprocess_data_iq(data_path, labels_path=None):\n",
    "\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "    \n",
    "    df['reanalysis_specific_humidity_g_per_kg_before'] = df['reanalysis_specific_humidity_g_per_kg']\n",
    "    df.reanalysis_specific_humidity_g_per_kg_before = df.reanalysis_specific_humidity_g_per_kg.shift(1)  \n",
    "    df['reanalysis_dew_point_temp_k_before'] = df['reanalysis_dew_point_temp_k']\n",
    "    df.reanalysis_dew_point_temp_k_before = df.reanalysis_dew_point_temp_k.shift(1) \n",
    "    df['reanalysis_air_temp_k_before'] = df['reanalysis_air_temp_k']\n",
    "    df.reanalysis_air_temp_k_before = df.reanalysis_air_temp_k.shift(1)  \n",
    "    df['reanalysis_min_air_temp_k_before'] = df['reanalysis_min_air_temp_k']\n",
    "    df.reanalysis_min_air_temp_k_before = df.reanalysis_min_air_temp_k.shift(1)  \n",
    "    df['station_avg_temp_c_before'] = df['station_avg_temp_c']\n",
    "    df.station_avg_temp_c_before = df.station_avg_temp_c.shift(1) \n",
    "    df['station_min_temp_c_before'] = df['station_min_temp_c']\n",
    "    df.station_min_temp_c_before = df.station_min_temp_c.shift(1)  \n",
    "    df['reanalysis_max_air_temp_k_before'] = df['reanalysis_max_air_temp_k']\n",
    "    df.reanalysis_max_air_temp_k_before = df.reanalysis_max_air_temp_k.shift(1)\n",
    "    \n",
    "# 將所有欄位都新增上週資料,取相關係數0.2以上且不重複\n",
    "    features = [\n",
    "#                  'reanalysis_specific_humidity_g_per_kg', \n",
    "#                  'reanalysis_dew_point_temp_k', \n",
    "#                  'reanalysis_min_air_temp_k', \n",
    "#                  'station_min_temp_c'\n",
    "        \n",
    "#                 \"station_min_temp_c\",\n",
    "#                 \"station_min_temp_c_before\",\n",
    "#                 \"reanalysis_min_air_temp_k\",\n",
    "                \"station_min_temp_c_before\",\n",
    "                \"reanalysis_min_air_temp_k\",\n",
    "                \"reanalysis_dew_point_temp_k\",\n",
    "                \"reanalysis_specific_humidity_g_per_kg\"\n",
    "\n",
    "               ]\n",
    "    df = df[features]\n",
    "    \n",
    "\n",
    "#     df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "  \n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    iq = df.loc['iq']\n",
    "    \n",
    "    return iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 呼叫function 建立training data\n",
    "sj_train = preprocess_data_sj('dengue_features_train.csv',labels_path=\"dengue_labels_train.csv\")\n",
    "iq_train = preprocess_data_iq('dengue_features_train.csv',labels_path=\"dengue_labels_train.csv\")\n",
    "\n",
    "# sj_train = sj_train.query('year != 1991')\n",
    "# sj_train = sj_train.query('year != 1991').query('year != 1994')\n",
    "# # sj_train = sj_train.query('weekofyear != 53')\n",
    "# iq_train = iq_train.query('weekofyear != 1').query('weekofyear != 52').query('weekofyear != 53')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除'total_cases'outlier\n",
    "def outlierout(train):\n",
    "#     train = train[np.abs(train[\"total_cases\"]-train[\"total_cases\"].mean())<=(7*train[\"total_cases\"].std())] #25.3438\n",
    "    train = train[np.abs(train[\"total_cases\"]-train[\"total_cases\"].mean())<=(6*train[\"total_cases\"].std())] #25.2692\n",
    "#     train = train[np.abs(train[\"total_cases\"]-train[\"total_cases\"].mean())<=(5*train[\"total_cases\"].std())] #25.6779\n",
    "    return train\n",
    "\n",
    "sj_train = outlierout(sj_train)\n",
    "iq_train = outlierout(iq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #取Log讓資料接近常態分配\n",
    "# sj_train[\"total_cases\"] = np.log(sj_train[\"total_cases\"])\n",
    "# iq_train[\"total_cases\"] = np.log(iq_train[\"total_cases\"])\n",
    "\n",
    "# #將取完log後，total_cases產生的最大下界(-inf)轉為nan 並 去除該列\n",
    "# sj_train = sj_train.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"total_cases\"], how=\"all\")\n",
    "# iq_train = iq_train.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"total_cases\"], how=\"all\")\n",
    "\n",
    "# print(sj_train[\"total_cases\"].values)\n",
    "# sj_train[\"total_cases\"].shape\n",
    "\n",
    "# #觀察 total_cases，發現資料非常態分配，透過取Log的方式讓資料接近常態分配也可讓預估上更準確\n",
    "# sj_Labels = sj_train[\"total_cases\"]\n",
    "# iq_Labels = iq_train[\"total_cases\"]\n",
    "# sj_LabelsLog = np.log(sj_Labels)\n",
    "# iq_LabelsLog = np.log(iq_Labels)\n",
    "# # sj_Labels.head()\n",
    "# # sj_LabelsLog.head()\n",
    "\n",
    "# # sj labels\n",
    "# plt.figure(figsize=(5,4))\n",
    "# sns.barplot(sj_Labels.index, sj_Labels.values, alpha=0.6) \n",
    "# plt.title(\"sj_Labels\", fontsize=16)\n",
    "# plt.xlabel(\"sj_Labels 1990-2008\", fontsize=12)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(5,4)) \n",
    "# sns.barplot(sj_LabelsLog.index, sj_LabelsLog.values, alpha=0.6) \n",
    "# plt.title(\"sj_LabelsLog\", fontsize=16)\n",
    "# plt.xlabel(\"sj_LabelsLog 1990-2008\", fontsize=12)\n",
    "# plt.show()\n",
    "\n",
    "# # iq labels\n",
    "# plt.figure(figsize=(5,4))\n",
    "# sns.barplot(iq_Labels.index, iq_Labels.values, alpha=0.6) \n",
    "# plt.title(\"iq_Labels\", fontsize=16)\n",
    "# plt.xlabel(\"iq_Labels 1990-2008\", fontsize=12)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(5,4)) \n",
    "# sns.barplot(iq_LabelsLog.index, iq_LabelsLog.values, alpha=0.6) \n",
    "# plt.title(\"iq_LabelsLog\", fontsize=16)\n",
    "# plt.xlabel(\"iq_LabelsLog 1990-2008\", fontsize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reanalysis_min_air_temp_k_before</th>\n",
       "      <th>reanalysis_max_air_temp_k_before</th>\n",
       "      <th>station_avg_temp_c_before</th>\n",
       "      <th>reanalysis_dew_point_temp_k_before</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg_before</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>928.000000</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>928.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>297.291810</td>\n",
       "      <td>301.383836</td>\n",
       "      <td>26.986469</td>\n",
       "      <td>295.094255</td>\n",
       "      <td>16.537346</td>\n",
       "      <td>31.081897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296771</td>\n",
       "      <td>1.264526</td>\n",
       "      <td>1.420471</td>\n",
       "      <td>1.577186</td>\n",
       "      <td>1.567794</td>\n",
       "      <td>39.085912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>292.600000</td>\n",
       "      <td>297.800000</td>\n",
       "      <td>22.842857</td>\n",
       "      <td>289.642857</td>\n",
       "      <td>11.715714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>296.300000</td>\n",
       "      <td>300.400000</td>\n",
       "      <td>25.785714</td>\n",
       "      <td>293.823571</td>\n",
       "      <td>15.207500</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>297.500000</td>\n",
       "      <td>301.500000</td>\n",
       "      <td>27.192857</td>\n",
       "      <td>295.437143</td>\n",
       "      <td>16.820714</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>298.400000</td>\n",
       "      <td>302.400000</td>\n",
       "      <td>28.171429</td>\n",
       "      <td>296.420000</td>\n",
       "      <td>17.862143</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299.900000</td>\n",
       "      <td>304.300000</td>\n",
       "      <td>30.071429</td>\n",
       "      <td>297.795714</td>\n",
       "      <td>19.440000</td>\n",
       "      <td>333.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reanalysis_min_air_temp_k_before  reanalysis_max_air_temp_k_before  \\\n",
       "count                        928.000000                        928.000000   \n",
       "mean                         297.291810                        301.383836   \n",
       "std                            1.296771                          1.264526   \n",
       "min                          292.600000                        297.800000   \n",
       "25%                          296.300000                        300.400000   \n",
       "50%                          297.500000                        301.500000   \n",
       "75%                          298.400000                        302.400000   \n",
       "max                          299.900000                        304.300000   \n",
       "\n",
       "       station_avg_temp_c_before  reanalysis_dew_point_temp_k_before  \\\n",
       "count                 928.000000                          928.000000   \n",
       "mean                   26.986469                          295.094255   \n",
       "std                     1.420471                            1.577186   \n",
       "min                    22.842857                          289.642857   \n",
       "25%                    25.785714                          293.823571   \n",
       "50%                    27.192857                          295.437143   \n",
       "75%                    28.171429                          296.420000   \n",
       "max                    30.071429                          297.795714   \n",
       "\n",
       "       reanalysis_specific_humidity_g_per_kg_before  total_cases  \n",
       "count                                    928.000000   928.000000  \n",
       "mean                                      16.537346    31.081897  \n",
       "std                                        1.567794    39.085912  \n",
       "min                                       11.715714     0.000000  \n",
       "25%                                       15.207500     9.000000  \n",
       "50%                                       16.820714    19.000000  \n",
       "75%                                       17.862143    37.000000  \n",
       "max                                       19.440000   333.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看San Juan數值資料\n",
    "sj_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_min_temp_c_before</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.198069</td>\n",
       "      <td>292.870270</td>\n",
       "      <td>295.494264</td>\n",
       "      <td>17.097471</td>\n",
       "      <td>7.210425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.276918</td>\n",
       "      <td>1.661862</td>\n",
       "      <td>1.416757</td>\n",
       "      <td>1.445318</td>\n",
       "      <td>9.081201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.700000</td>\n",
       "      <td>286.900000</td>\n",
       "      <td>290.088571</td>\n",
       "      <td>12.111429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.600000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>294.593214</td>\n",
       "      <td>16.110000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.300000</td>\n",
       "      <td>293.050000</td>\n",
       "      <td>295.852143</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>294.200000</td>\n",
       "      <td>296.559286</td>\n",
       "      <td>18.190000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.200000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>298.450000</td>\n",
       "      <td>20.461429</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_min_temp_c_before  reanalysis_min_air_temp_k  \\\n",
       "count                 518.000000                 518.000000   \n",
       "mean                   21.198069                 292.870270   \n",
       "std                     1.276918                   1.661862   \n",
       "min                    14.700000                 286.900000   \n",
       "25%                    20.600000                 292.000000   \n",
       "50%                    21.300000                 293.050000   \n",
       "75%                    22.000000                 294.200000   \n",
       "max                    24.200000                 296.000000   \n",
       "\n",
       "       reanalysis_dew_point_temp_k  reanalysis_specific_humidity_g_per_kg  \\\n",
       "count                   518.000000                             518.000000   \n",
       "mean                    295.494264                              17.097471   \n",
       "std                       1.416757                               1.445318   \n",
       "min                     290.088571                              12.111429   \n",
       "25%                     294.593214                              16.110000   \n",
       "50%                     295.852143                              17.428571   \n",
       "75%                     296.559286                              18.190000   \n",
       "max                     298.450000                              20.461429   \n",
       "\n",
       "       total_cases  \n",
       "count   518.000000  \n",
       "mean      7.210425  \n",
       "std       9.081201  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       5.000000  \n",
       "75%       9.000000  \n",
       "max      63.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看Iquitos數值資料\n",
    "iq_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sj_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iq_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.資料分割 > 建模 > 訓練 > 評估 > 預測 > 輸出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice1 :SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=31)\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "\n",
    "# from sklearn import svm, grid_search\n",
    "# def svc_param_selection(X, y, nfolds):\n",
    "#     Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "#     gammas = [0.001, 0.01, 0.1, 1]\n",
    "#     param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "#     grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "#     grid_search.fit(X, y)\n",
    "#     grid_search.best_params_\n",
    "#     return grid_search.best_params_\n",
    "\n",
    "# print(svc_param_selection(X_train_sj_std, y_train_sj, 10))\n",
    "\n",
    "\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# # clf_sj = SVR(C=0.001,gamma=0.1)\n",
    "# clf_sj = SVR(kernel='poly', \n",
    "#             degree=5, \n",
    "#             gamma='auto',\n",
    "#             coef0=0.0, \n",
    "#             tol=0.0001, \n",
    "#             C=2.0, \n",
    "#             epsilon=0.1, \n",
    "#             shrinking=True, \n",
    "#             cache_size=200, \n",
    "#             verbose=False, \n",
    "#             max_iter=-1)\n",
    "\n",
    "\n",
    "# clf_sj.fit(X_train_sj_std, y_train_sj)\n",
    "# y_pred_sj = clf_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(clf_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "\n",
    "# ###########################################################################################################################\n",
    "\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = clf_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice2 :RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # sj rfRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,test_size=0.3,random_state=31)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# rfModel_sj = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "#                                    max_features='auto', max_leaf_nodes=5,\n",
    "#                                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                                    min_samples_leaf=3, min_samples_split=2,\n",
    "#                                    min_weight_fraction_leaf=0.0,n_jobs=1,\n",
    "#                                    oob_score=False, verbose=0, warm_start=False,\n",
    "#                                    n_estimators=2000,random_state=31)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rfModel_sj.fit(X_train_sj_std,y_train_sj) \n",
    "# y_pred_sj = rfModel_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(rfModel_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# # #######################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = rfModel_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iq rfRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# X = iq_train.iloc[:,0:-1].values\n",
    "# y = iq_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_iq,X_test_iq,y_train_iq,y_test_iq = cross_validation.train_test_split(X,y,test_size=0.175,random_state=201)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_iq_std = sc.fit_transform(X_train_iq)\n",
    "# X_test_iq_std = sc.transform(X_test_iq)\n",
    "\n",
    "# rfModel_iq = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "#                                    max_features='auto', max_leaf_nodes=5,\n",
    "#                                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                                    min_samples_leaf=3, min_samples_split=2,\n",
    "#                                    min_weight_fraction_leaf=0.0,n_jobs=1,\n",
    "#                                    oob_score=False, verbose=0, warm_start=False,\n",
    "#                                    n_estimators=2000,random_state=31)\n",
    "\n",
    "\n",
    "# rfModel_iq.fit(X_train_iq_std, y_train_iq)\n",
    "# y_pred_iq = rfModel_iq.predict(X_test_iq_std)\n",
    "# print(\"Score:\"+str(rfModel_iq.score(X_test_iq_std, y_test_iq)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_iq, y_pred_iq)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_iq, y_pred_iq))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_iq, y_pred_iq)))\n",
    "# #######################################################################\n",
    "# iq_test = preprocess_data_iq('dengue_features_test.csv')\n",
    "\n",
    "# X2 = iq_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_iq = rfModel_iq.predict(X2_std).astype(int)\n",
    "# print(total_cases_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice3 :Bagging(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                           test_size=0.3,\n",
    "#                                                                           random_state=31)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# ensemble = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
    "#                             n_estimators=7,\n",
    "#                             max_samples=1.0,\n",
    "#                             max_features=1.0,\n",
    "# #                             bootstrap=True,\n",
    "# #                             oob_score=False,\n",
    "#                             bootstrap_features=False,\n",
    "#                             n_jobs=4,\n",
    "#                             verbose=0,\n",
    "#                             random_state=31).fit(X_train_sj_std, y_train_sj)\n",
    "\n",
    "# ensemble.fit(X_train_sj_std,y_train_sj) \n",
    "# y_pred_sj = ensemble.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(ensemble.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# # #######################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = ensemble.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice4 :XGBoost(XGBRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,test_size=0.3,random_state=31)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# xgb1 = XGBRegressor()\n",
    "# parameters = {'nthread':[4, 5, 6], #when use hyperthread, xgboost may become slower\n",
    "#               'objective':['reg:linear'],\n",
    "#               'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "#               'max_depth': [5, 6, 7],\n",
    "#               'min_child_weight': [3, 4, 5, 6],\n",
    "#               'silent': [1],\n",
    "#               'subsample': [0.5],\n",
    "#               'colsample_bytree': [0.5],\n",
    "#               'n_estimators': [500]\n",
    "#              }\n",
    "\n",
    "# xgb_grid = GridSearchCV(xgb1,\n",
    "#                         parameters,\n",
    "#                         cv = 4,\n",
    "#                         n_jobs = 5,\n",
    "#                         verbose=True)\n",
    "\n",
    "# xgb_grid.fit(X_train_sj_std, y_train_sj)\n",
    "\n",
    "# print(xgb_grid.best_score_)\n",
    "# print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_sj = XGBRegressor(\n",
    "#             nthread = 4, \n",
    "#             silent = 1,\n",
    "#             max_depth = 5,\n",
    "#             objective = 'reg:linear',\n",
    "#             n_estimators = 55,\n",
    "#             learning_rate = 0.01, \n",
    "#             n_jobs = - 1,\n",
    "#             subsample = 0.9,\n",
    "#             colsample_bytree = 0.6,\n",
    "#             colsample_bylevel = 0.1,\n",
    "#             min_child_weight = 5,\n",
    "#             reg_alpha = 0.1\n",
    "#           )\n",
    "\n",
    "# xgb_sj.fit(X_train_sj_std,y_train_sj) \n",
    "# y_pred_sj = xgb_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(xgb_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# # #######################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = xgb_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice5 :Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## sj Lasso\n",
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "# #25.4399\n",
    "# # lasso_sj = Lasso(alpha=0.008, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# #25.4207\n",
    "# # lasso_sj = Lasso(alpha=0.0008, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# # #25.3606\n",
    "# # lasso_sj = Lasso(alpha=0.0008, copy_X=True, fit_intercept=True, max_iter=2000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "\n",
    "# lasso_sj = Lasso(alpha=0.00008, copy_X=True, fit_intercept=True, max_iter=3000,\n",
    "#                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "#                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=31)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# lasso_sj.fit(X_train_sj_std, y_train_sj)\n",
    "# y_pred_sj = lasso_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(lasso_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# ########################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = lasso_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iq lasso\n",
    "# from sklearn.linear_model import Lasso\n",
    "# # lasso_iq = Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "# #                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "# #                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# lasso_iq = Lasso(alpha=0.00008, copy_X=True, fit_intercept=True, max_iter=3000,\n",
    "#                    normalize=False, positive=False, precompute=False, random_state=None,\n",
    "#                    selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "# X = iq_train.iloc[:,0:-1].values\n",
    "# y = iq_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_iq,X_test_iq,y_train_iq,y_test_iq = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=209)\n",
    "# sc = StandardScaler()\n",
    "# X_train_iq_std = sc.fit_transform(X_train_iq)\n",
    "# X_test_iq_std = sc.transform(X_test_iq)\n",
    "\n",
    "# lasso_iq.fit(X_train_iq_std, y_train_iq)\n",
    "# y_pred_iq = lasso_iq.predict(X_test_iq_std)\n",
    "# print(\"Score:\"+str(lasso_iq.score(X_test_iq_std, y_test_iq)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_iq, y_pred_iq)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_iq, y_pred_iq))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_iq, y_pred_iq)))\n",
    "# #######################################################################\n",
    "# iq_test = preprocess_data_iq('dengue_features_test.csv')\n",
    "\n",
    "# X2 = iq_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_iq = lasso_iq.predict(X2_std).astype(int)\n",
    "# print(total_cases_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice6 :Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sj Ridge\n",
    "X = sj_train.iloc[:,0:-1].values\n",
    "y = sj_train.iloc[:,-1].values\n",
    "\n",
    "X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,test_size=0.3,random_state=373)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgecv_sj = RidgeCV(alphas=[0.0001, 0.0001, 0.01, 0.1, 0.15, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.17, 0.18, 0.19, 0.2, 0.25, 0.3])\n",
    "ridgecv_sj.fit(X_train_sj_std, y_train_sj)\n",
    "ridgecv_sj.alpha_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.05281777226703976\n",
      "MAE:22.40270659119176\n",
      "MSE: 1295.5474574920754\n",
      "RMSE: 35.993714138611416\n",
      "[23 23 23 26 21 24 26 30 36 37 38 33 35 40 37 50 48 49 54 64 60 51 47 50\n",
      " 40 42 38 32 43 38 37 27 20 18 21 20 19 19 19 18 21 16 15 17 14 16 21 17\n",
      " 17 19 16 15 16 18 16 24 23 40 31 31 36 33 36 39 43 44 44 41 43 46 52 45\n",
      " 48 44 42 51 51 53 50 39 36 38 44 45 32 32 29 27 25 25 23 26 26 18 19 24\n",
      " 24 36 28 27 32 27 26 19 32 47 40 35 39 43 63 56 49 51 55 57 60 55 55 53\n",
      " 59 57 59 61 62 60 55 52 58 63 47 37 39 46 33 21 21 28 27 23 11 17 22 18\n",
      " 17 12 12 12 13 12 12 17 10 16 19 11 15 14 21 15 24 37 42 42 57 51 46 46\n",
      " 44 40 50 44 53 48 54 52 42 51 45 47 51 40 38 31 43 37 37 30 28 21 27 15\n",
      " 15 17 15 12 10 10 12 12 11 10 10  9  9 14 16 18 17 21 24 22 35 30 21 33\n",
      " 29 33 35 34 37 41 42 37 42 48 43 41 34 33 35 43 43 37 53 47 49 37 36 40\n",
      " 29 24 18 17 16 14 11 11 13 13 13 11 11 14 17 18 18 15 17 17]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#25.3317\n",
    "# ridge_sj = Ridge(alpha=0.0015)\n",
    "\n",
    "#25.3534\n",
    "# ridge_sj = Ridge(alpha=0.000015, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "#                  normalize=False, random_state=None, solver='sag', tol=0.001)\n",
    "\n",
    "#25.3269、25.3173、25.2692 (去除 >6倍std的outlier)\n",
    "ridge_sj = Ridge(alpha=0.00015)\n",
    "\n",
    "\n",
    "ridge_sj.fit(X_train_sj_std,y_train_sj) \n",
    "y_pred_sj = ridge_sj.predict(X_test_sj_std)\n",
    "print(\"Score:\"+str(ridge_sj.score(X_test_sj_std, y_test_sj)))\n",
    "print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# #######################################################################\n",
    "sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "X2 = sj_test.values\n",
    "X2_std = sc.transform(X2)\n",
    "\n",
    "total_cases_sj = ridge_sj.predict(X2_std).astype(int)\n",
    "# total_cases_sj = np.exp(ridge_sj.predict(X2_std)).astype(int)\n",
    "print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iq Ridge\n",
    "X = iq_train.iloc[:,0:-1].values\n",
    "y = iq_train.iloc[:,-1].values\n",
    "\n",
    "#25.3173、25.2692 (去除 >6倍std的outlier)\n",
    "X_train_iq,X_test_iq,y_train_iq,y_test_iq = cross_validation.train_test_split(X,y,test_size=0.175,random_state=201)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_iq_std = sc.fit_transform(X_train_iq)\n",
    "X_test_iq_std = sc.transform(X_test_iq)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgecv_iq = RidgeCV(alphas=[0.0001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.4, 0.5, 1])\n",
    "ridgecv_iq.fit(X_train_iq_std, y_train_iq)\n",
    "ridgecv_iq.alpha_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.04044243888496579\n",
      "MAE:5.965851603362371\n",
      "MSE: 93.5610916316093\n",
      "RMSE: 9.672698260134517\n",
      "[ 7  5  7  5  0  3  5  4  5  6  6  6  7  4  6  6  7  8 12  7  7  9  9 10\n",
      "  9  7  7  7  8  7  6  6  7  8  8  9  7  8  9  9  9  7  7  8 10  4  6  7\n",
      "  5  3  4  2  3  4  2  3  4  4  4  3  5  1  2  6  6  7  7  8 10  8  6  8\n",
      "  9  9  8 10  8  8 10  8  8  8  6  8  9  8  7  6  7  6  6  8  6  9 10  8\n",
      "  8  5  5  5  5  6  3  3  4  3  3  5  0  1  2  1  3  4  4  4  5  5  3  8\n",
      "  8  9  9  8 10 11 12 10 10 10  9  7  6  9  8 11  9 10  8  9 10 11 11  9\n",
      "  8 10  8  3  6  8  6  7  7  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#25.3317\n",
    "# ridge_iq = Ridge(alpha=0.27)\n",
    "\n",
    "#25.3269\n",
    "# ridge_iq = Ridge(alpha=0.275)\n",
    "\n",
    "#25.3534\n",
    "# ridge_iq = Ridge(alpha=0.276, copy_X=True, fit_intercept=True, max_iter=None,normalize=False, random_state=None, solver='sag', tol=0.001)\n",
    "\n",
    "#25.3173\n",
    "ridge_iq = Ridge(alpha=0.275)\n",
    "\n",
    "\n",
    "ridge_iq.fit(X_train_iq_std,y_train_iq) \n",
    "y_pred_iq = ridge_iq.predict(X_test_iq_std)\n",
    "print(\"Score:\"+str(ridge_iq.score(X_test_iq_std, y_test_iq)))\n",
    "print(\"MAE:\"+str(mean_absolute_error(y_test_iq, y_pred_iq)))\n",
    "print(\"MSE:\",metrics.mean_squared_error(y_test_iq, y_pred_iq))\n",
    "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_iq, y_pred_iq)))\n",
    "# #######################################################################\n",
    "iq_test = preprocess_data_iq('dengue_features_test.csv')\n",
    "\n",
    "X2 = iq_test.values\n",
    "X2_std = sc.transform(X2)\n",
    "\n",
    "total_cases_iq = ridge_iq.predict(X2_std).astype(int)\n",
    "# total_cases_iq = np.exp(ridge_iq.predict(X2_std)).astype(int)\n",
    "print(total_cases_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第266欄位 負數值補0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice7 :Liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## model sj\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# regr_sj = linear_model.LinearRegression()\n",
    "\n",
    "# X = sj_train.iloc[:,0:-1].values\n",
    "# y = sj_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_sj,X_test_sj,y_train_sj,y_test_sj = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=31)\n",
    "# sc = StandardScaler()\n",
    "# X_train_sj_std = sc.fit_transform(X_train_sj)\n",
    "# X_test_sj_std = sc.transform(X_test_sj)\n",
    "\n",
    "# regr_sj.fit(X_train_sj_std, y_train_sj)\n",
    "# y_pred_sj = regr_sj.predict(X_test_sj_std)\n",
    "# print(\"Score:\"+str(regr_sj.score(X_test_sj_std, y_test_sj)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_sj, y_pred_sj)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_sj, y_pred_sj))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_sj, y_pred_sj)))\n",
    "# #######################################################################\n",
    "# sj_test = preprocess_data_sj('dengue_features_test.csv')\n",
    "\n",
    "# X2 = sj_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_sj = regr_sj.predict(X2_std).astype(int)\n",
    "# print(total_cases_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # model iq\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# regr_iq = linear_model.LinearRegression()\n",
    "\n",
    "# X = iq_train.iloc[:,0:-1].values\n",
    "# y = iq_train.iloc[:,-1].values\n",
    "\n",
    "# X_train_iq,X_test_iq,y_train_iq,y_test_iq = cross_validation.train_test_split(X,y,\n",
    "#                                                                               test_size=0.3,\n",
    "#                                                                               random_state=201)\n",
    "# sc = StandardScaler()\n",
    "# X_train_iq_std = sc.fit_transform(X_train_iq)\n",
    "# X_test_iq_std = sc.transform(X_test_iq)\n",
    "\n",
    "# regr_iq.fit(X_train_iq_std, y_train_iq)\n",
    "# y_pred_iq = regr_iq.predict(X_test_iq_std)\n",
    "# print(\"Score:\"+str(regr_iq.score(X_test_iq_std, y_test_iq)))\n",
    "# print(\"MAE:\"+str(mean_absolute_error(y_test_iq, y_pred_iq)))\n",
    "# print(\"MSE:\",metrics.mean_squared_error(y_test_iq, y_pred_iq))\n",
    "# print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test_iq, y_pred_iq)))\n",
    "# #######################################################################\n",
    "# iq_test = preprocess_data_iq('dengue_features_test.csv')\n",
    "\n",
    "# X2 = iq_test.values\n",
    "# X2_std = sc.transform(X2)\n",
    "\n",
    "# total_cases_iq = regr_iq.predict(X2_std).astype(int)\n",
    "# print(total_cases_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將預測結果 numpy轉pandas\n",
    "total_cases_sj =pd.DataFrame({\"total_cases\": total_cases_sj})\n",
    "total_cases_iq =pd.DataFrame({\"total_cases\": total_cases_iq})\n",
    "total_cases_all = pd.concat([total_cases_sj,total_cases_iq], axis=0).reset_index()    \n",
    "        \n",
    "#  讀取submission_format\n",
    "submission_format = pd.read_csv('submission_format.csv')\n",
    "submission_format = submission_format.drop(['total_cases'], axis=1)\n",
    "submission_format.head()  \n",
    "    \n",
    "# 合併submission_format及輸出結果\n",
    "submission = pd.concat([submission_format,total_cases_all['total_cases']], axis=1) \n",
    "submission  \n",
    "\n",
    "# 輸出csv檔\n",
    "submission.to_csv('output0713_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
